{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from pprint import pprint\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction import DictVectorizer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression, HuberRegressor\n",
    "from sklearn.naive_bayes import MultinomialNB, GaussianNB, BernoulliNB\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.externals import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sents = pd.read_pickle('../data/processed-my-ingredients.pickle')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change Sents to Features & Labels!\n",
    "\n",
    "def sents_to_features(sents):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for token in sents:\n",
    "        num_words = len(token['lemma'])\n",
    "        for i in range(num_words):\n",
    "            features.append({\n",
    "                'word': token['lemma'][i],\n",
    "                'pos': token['pos'][i],\n",
    "                'tag': token['tag'][i],\n",
    "                'is_alpha': token['is_alpha'][i],\n",
    "                'is_num': token['is_num'][i],\n",
    "                'is_start': i == 0,\n",
    "                'is_end': i == num_words - 1,\n",
    "#                 'prev_word': token['lemma'][i-1] if i-1 >= 0 else '',\n",
    "                'prev_pos': token['pos'][i-1] if i-1 >= 0 else '',\n",
    "                'prev_tag': token['tag'][i-1] if i-1 >= 0 else '',\n",
    "                'prev_is_num': token['is_num'][i-1] if i-1 >= 0 else '',\n",
    "#                 'next_word': token['lemma'][i+1] if i+1 < num_words else '',\n",
    "                'next_pos': token['pos'][i+1] if i+1 < num_words else '',\n",
    "                'next_tag': token['tag'][i+1] if i+1 < num_words else '',\n",
    "                'next_is_num': token['is_num'][i+1] if i+1 < num_words else '',\n",
    "            })\n",
    "            labels.append(token['label'][i])\n",
    "    return features, labels\n",
    "\n",
    "features, labels = sents_to_features(sents)\n",
    "pickle.dump((features, labels), open('../data/features-my-ingredients.pickle', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num Recipes: 654788\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'word': '4.0',\n",
       " 'pos': 'NUM',\n",
       " 'tag': 'CD',\n",
       " 'is_alpha': False,\n",
       " 'is_num': True,\n",
       " 'is_start': True,\n",
       " 'is_end': False,\n",
       " 'prev_pos': '',\n",
       " 'prev_tag': '',\n",
       " 'prev_is_num': '',\n",
       " 'next_pos': 'PUNCT',\n",
       " 'next_tag': '-LRB-',\n",
       " 'next_is_num': False}"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Num Recipes:', len(features))\n",
    "features[8]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/Desktop/mealprep/nlp-ingredients/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Overview\n",
    "We are going to build several basic models trying to use more and more of the data provided. \n",
    "\n",
    "1. only pos / tag\n",
    "1. pos and tag\n",
    "1. pos, tag, is_alpha, is_num"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/Desktop/mealprep/nlp-ingredients/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/justin/Desktop/mealprep/nlp-ingredients/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Score:       0.8435333333333334\n",
      "Logistic Regression Score: 0.8635333333333334\n",
      "Multi. Naive Bayes Score:  0.8118\n",
      "Gauss Naive Bayes Score:   0.7548666666666667\n",
      "Bern Naive Bayes Score:    0.8061333333333334\n"
     ]
    }
   ],
   "source": [
    "clf_dt = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('decision_tree', DecisionTreeClassifier(criterion='entropy'))\n",
    "])\n",
    "clf_lr = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "clf_multi_nb = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('multi_nb', MultinomialNB())\n",
    "])\n",
    "clf_gaus_nb = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('gaus_nb', GaussianNB())\n",
    "])\n",
    "clf_bern_nb = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('bern_nb', BernoulliNB())\n",
    "])\n",
    "clf_dt.fit(X_train[:5000], y_train[:5000])\n",
    "clf_lr.fit(X_train[:5000], y_train[:5000])\n",
    "clf_multi_nb.fit(X_train[:5000], y_train[:5000])\n",
    "clf_gaus_nb.fit(X_train[:5000], y_train[:5000])\n",
    "clf_bern_nb.fit(X_train[:5000], y_train[:5000])\n",
    "print('Decision Tree Score:      ', clf_dt.score(X_test[:15000], y_test[:15000]))\n",
    "print('Logistic Regression Score:', clf_lr.score(X_test[:15000], y_test[:15000]))\n",
    "print('Multi. Naive Bayes Score: ', clf_multi_nb.score(X_test[:15000], y_test[:15000]))\n",
    "print('Gauss Naive Bayes Score:  ', clf_gaus_nb.score(X_test[:15000], y_test[:15000]))\n",
    "print('Bern Naive Bayes Score:   ', clf_bern_nb.score(X_test[:15000], y_test[:15000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVC Linear Score: 0.8739333333333333\n"
     ]
    }
   ],
   "source": [
    "# WARNING: these are very SLOW!\n",
    "# clf_svc_rbf = Pipeline([\n",
    "#     ('vectorizer', DictVectorizer(sparse=False)),\n",
    "#     ('svc', SVC())\n",
    "# ])\n",
    "clf_svc_linear = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('svc', SVC(kernel='linear'))\n",
    "])\n",
    "# clf_svc_rbf.fit(X_train[:5000], y_train[:5000])\n",
    "clf_svc_linear.fit(X_train[:5000], y_train[:5000])\n",
    "# print('SVC RBF Score:   ', clf_svc_rbf.score(X_test[:15000], y_test[:15000]))\n",
    "print('SVC Linear Score:', clf_svc_linear.score(X_test[:15000], y_test[:15000]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Best Models\n",
    "1. Logistic Regression - 86.4%\n",
    "1. Linear SVC - 86.9%\n",
    "1. Decition Tree - 84.4%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/justin/Desktop/mealprep/nlp-ingredients/env/lib/python3.6/site-packages/sklearn/model_selection/_split.py:2179: FutureWarning: From version 0.21, test_size will always complement train_size unless both are specified.\n",
      "  FutureWarning)\n",
      "/Users/justin/Desktop/mealprep/nlp-ingredients/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "/Users/justin/Desktop/mealprep/nlp-ingredients/env/lib/python3.6/site-packages/sklearn/linear_model/logistic.py:460: FutureWarning: Default multi_class will be changed to 'auto' in 0.22. Specify the multi_class option to silence this warning.\n",
      "  \"this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Score: 0.9278606205367234\n"
     ]
    }
   ],
   "source": [
    "def sents_to_features(sents):\n",
    "    features = []\n",
    "    labels = []\n",
    "    for token in sents:\n",
    "        num_words = len(token['lemma'])\n",
    "        for i in range(num_words):\n",
    "            features.append({\n",
    "                # Current Word\n",
    "                'word': token['lemma'][i],\n",
    "#                 'pos': token['pos'][i],\n",
    "                'tag': token['tag'][i],\n",
    "#                 'is_alpha': token['is_alpha'][i],\n",
    "#                 'is_num': token['is_num'][i],\n",
    "#                 'is_start': i == 0,\n",
    "#                 'is_end': i == num_words - 1,\n",
    "#                 # Prev Word\n",
    "                'prev_word': token['lemma'][i-1] if i-1 >= 0 else '',\n",
    "#                 'prev_pos': token['pos'][i-1] if i-1 >= 0 else '',\n",
    "                'prev_tag': token['tag'][i-1] if i-1 >= 0 else '',\n",
    "#                 'prev_is_alpha': token['is_alpha'][i-1] if i-1 >= 0 else '',\n",
    "#                 'prev_is_num': token['is_num'][i-1] if i-1 >= 0 else '',\n",
    "#                 # Prev Prev Word\n",
    "                'prev_prev_word': token['lemma'][i-2] if i-2 >= 0 else '',\n",
    "#                 'prev_prev_pos': token['pos'][i-2] if i-2 >= 0 else '',\n",
    "                'prev_prev_tag': token['tag'][i-2] if i-2 >= 0 else '',\n",
    "#                 'prev_prev_is_num': token['is_num'][i-2] if i-2 >= 0 else '',\n",
    "#                 # Next Word\n",
    "                'next_word': token['lemma'][i+1] if i+1 < num_words else '',\n",
    "#                 'next_pos': token['pos'][i+1] if i+1 < num_words else '',\n",
    "                'next_tag': token['tag'][i+1] if i+1 < num_words else '',\n",
    "#                 'next_is_num': token['is_num'][i+1] if i+1 < num_words else '',\n",
    "#                 # Next Next\n",
    "                'next_next_word': token['lemma'][i+2] if i+2 < num_words else '',\n",
    "#                 'next_next_pos': token['pos'][i+2] if i+2 < num_words else '',\n",
    "                'next_next_tag': token['tag'][i+2] if i+2 < num_words else '',\n",
    "#                 'next_next_is_num': token['is_num'][i+2] if i+2 < num_words else '',\n",
    "            })\n",
    "            labels.append(token['label'][i])\n",
    "    return features, labels\n",
    "\n",
    "features, labels = sents_to_features(sents)\n",
    "X_train, X_test, y_train, y_test = train_test_split(features, labels, train_size=0.75)\n",
    "\n",
    "clf_lr = Pipeline([\n",
    "    ('vectorizer', DictVectorizer(sparse=False)),\n",
    "    ('log_reg', LogisticRegression())\n",
    "])\n",
    "# clf_dt = Pipeline([\n",
    "#     ('vectorizer', DictVectorizer(sparse=False)),\n",
    "#     ('decision_tree', DecisionTreeClassifier(criterion='entropy'))\n",
    "# ])\n",
    "# clf_svc_linear = Pipeline([\n",
    "#     ('vectorizer', DictVectorizer(sparse=False)),\n",
    "#     ('svc', SVC(kernel='linear'))\n",
    "# ])\n",
    "clf_lr.fit(X_train[:275000], y_train[:275000])\n",
    "print('Logistic Regression Score:', clf_lr.score(X_test, y_test))\n",
    "# clf_dt.fit(X_train[:50000], y_train[:50000])\n",
    "# print('Decision Tree Score:', clf_dt.score(X_test[:75000], y_test[:75000]))\n",
    "# clf_svc_linear.fit(X_train[:50000], y_train[:50000])\n",
    "# print('SVC Linear Score:', clf_svc_linear.score(X_test[:75000], y_test[:75000]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['salt',\n",
      " 'sheet',\n",
      " 'slice',\n",
      " 'small',\n",
      " 'parmesan',\n",
      " 'lettuce',\n",
      " 'meat',\n",
      " ',',\n",
      " 'small',\n",
      " 'juice',\n",
      " '3.0',\n",
      " 'large',\n",
      " '(',\n",
      " '3.5',\n",
      " ')']\n",
      "array(['NAME', 'UNIT', 'COMMENT', 'COMMENT', 'NAME', 'NAME', 'NAME',\n",
      "       'PUNCTUATION', 'COMMENT', 'NAME', 'QUANTITY', 'COMMENT',\n",
      "       'PUNCTUATION', 'QUANTITY', 'PUNCTUATION'], dtype='<U11')\n"
     ]
    }
   ],
   "source": [
    "ex = X_train[10:25]\n",
    "pprint([t['word'] for t in ex])\n",
    "pprint(clf_lr.predict(ex))\n",
    "# pprint(clf_dt.predict(ex))\n",
    "# pprint(clf_svc_linear.predict(ex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['../data/logistic-regression-92.8.pickle']"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filename = '../data/logistic-regression-92.8.pickle'\n",
    "joblib.dump(clf_lr, filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf_lr = joblib.load(filename)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
